#!/usr/bin/env node

const https = require("https")
const fs = require("fs")
const path = require("path")

const baseUrl = "https://diplo-scanner.com"

// Pages avec probl√®mes d'indexation identifi√©s
const problematicUrls = [
  "/liste-codes-pays-plaques-diplomatiques-francaises",
  "/codes-diplomatiques-suisses",
  "/privileges-immunites-plaques-diplomatiques",
  "/plaque-immatriculation-verte",
  "/plaque-verte-et-orange",
  "/comment-lire-une-plaque-diplomatique-francaise",
  "/comment-lire-une-plaque-diplomatique-suisse",
  "/qu-est-ce-qu-une-plaque-diplomatique",
  "/swiss",
  "/french",
]

async function analyzeUrl(url) {
  return new Promise((resolve) => {
    const req = https.request(
      url,
      {
        method: "GET",
        headers: {
          "User-Agent": "Mozilla/5.0 (compatible; DiploScanner-Indexation-Bot/1.0)",
        },
      },
      (res) => {
        let data = ""
        res.on("data", (chunk) => {
          data += chunk
        })

        res.on("end", () => {
          // Analyse basique du contenu
          const analysis = {
            url,
            status: res.statusCode,
            headers: {
              "content-type": res.headers["content-type"],
              "content-length": res.headers["content-length"],
              "cache-control": res.headers["cache-control"],
              "x-robots-tag": res.headers["x-robots-tag"],
            },
            content: {
              hasTitle: data.includes("<title>"),
              hasMetaDescription: data.includes('name="description"'),
              hasCanonical: data.includes('rel="canonical"'),
              hasStructuredData: data.includes('"@type"'),
              hasH1: data.includes("<h1"),
              wordCount: data.split(/\s+/).length,
              hasInternalLinks: data.includes('href="/'),
            },
            seo: {
              titleLength: 0,
              metaDescriptionLength: 0,
              hasOpenGraph: data.includes('property="og:'),
              hasTwitterCard: data.includes('name="twitter:'),
            },
          }

          // Extraction du titre
          const titleMatch = data.match(/<title[^>]*>([^<]+)<\/title>/i)
          if (titleMatch) {
            analysis.seo.titleLength = titleMatch[1].length
          }

          // Extraction de la meta description
          const metaMatch = data.match(/<meta[^>]*name="description"[^>]*content="([^"]*)"[^>]*>/i)
          if (metaMatch) {
            analysis.seo.metaDescriptionLength = metaMatch[1].length
          }

          resolve(analysis)
        })
      },
    )

    req.on("error", (error) => {
      resolve({
        url,
        status: "ERROR",
        error: error.message,
      })
    })

    req.end()
  })
}

async function analyzeAllProblematicUrls() {
  console.log("üîç ANALYSE D'INDEXATION - PAGES PROBL√âMATIQUES")
  console.log("=".repeat(55))

  const results = []

  for (const urlPath of problematicUrls) {
    const fullUrl = `${baseUrl}${urlPath}`
    console.log(`\nAnalyse: ${fullUrl}`)

    const analysis = await analyzeUrl(fullUrl)
    results.push(analysis)

    if (analysis.status === 200) {
      console.log(`‚úÖ Status: ${analysis.status}`)
      console.log(`üìù Titre: ${analysis.seo.titleLength} caract√®res`)
      console.log(`üìÑ Meta description: ${analysis.seo.metaDescriptionLength} caract√®res`)
      console.log(`üîó Canonical: ${analysis.content.hasCanonical ? "‚úÖ" : "‚ùå"}`)
      console.log(`üìä Structured data: ${analysis.content.hasStructuredData ? "‚úÖ" : "‚ùå"}`)
      console.log(`üîç Mots: ~${Math.round(analysis.content.wordCount / 10) * 10}`)
    } else {
      console.log(`‚ùå Status: ${analysis.status}`)
      if (analysis.error) {
        console.log(`‚ùå Erreur: ${analysis.error}`)
      }
    }
  }

  return results
}

function generateIndexationReport(results) {
  console.log("\nüìä RAPPORT D'INDEXATION:")
  console.log("=".repeat(30))

  const summary = {
    total: results.length,
    success: results.filter((r) => r.status === 200).length,
    errors: results.filter((r) => r.status !== 200).length,
    seoIssues: [],
    recommendations: [],
  }

  // Analyse des probl√®mes SEO
  results.forEach((result) => {
    if (result.status === 200) {
      if (result.seo.titleLength === 0) {
        summary.seoIssues.push(`${result.url}: Titre manquant`)
      } else if (result.seo.titleLength > 60) {
        summary.seoIssues.push(`${result.url}: Titre trop long (${result.seo.titleLength} caract√®res)`)
      }

      if (result.seo.metaDescriptionLength === 0) {
        summary.seoIssues.push(`${result.url}: Meta description manquante`)
      } else if (result.seo.metaDescriptionLength > 160) {
        summary.seoIssues.push(
          `${result.url}: Meta description trop longue (${result.seo.metaDescriptionLength} caract√®res)`,
        )
      }

      if (!result.content.hasCanonical) {
        summary.seoIssues.push(`${result.url}: URL canonique manquante`)
      }

      if (!result.content.hasStructuredData) {
        summary.seoIssues.push(`${result.url}: Structured data manquantes`)
      }
    }
  })

  // Recommandations
  if (summary.seoIssues.length > 0) {
    summary.recommendations.push("Corriger les probl√®mes SEO identifi√©s")
  }
  summary.recommendations.push("Soumettre le sitemap √† Google Search Console")
  summary.recommendations.push("Demander l'indexation manuelle des pages")
  summary.recommendations.push("Am√©liorer les liens internes")
  summary.recommendations.push("Optimiser les Core Web Vitals")

  console.log(`üìà Pages analys√©es: ${summary.total}`)
  console.log(`‚úÖ Pages OK: ${summary.success}`)
  console.log(`‚ùå Pages en erreur: ${summary.errors}`)
  console.log(`‚ö†Ô∏è  Probl√®mes SEO: ${summary.seoIssues.length}`)

  if (summary.seoIssues.length > 0) {
    console.log("\n‚ö†Ô∏è  PROBL√àMES SEO D√âTECT√âS:")
    summary.seoIssues.forEach((issue) => console.log(`   ‚Ä¢ ${issue}`))
  }

  console.log("\nüöÄ RECOMMANDATIONS:")
  summary.recommendations.forEach((rec, index) => console.log(`   ${index + 1}. ${rec}`))

  return summary
}

async function main() {
  try {
    // Analyse de toutes les URLs probl√©matiques
    const results = await analyzeAllProblematicUrls()

    // G√©n√©ration du rapport
    const summary = generateIndexationReport(results)

    // Sauvegarde du rapport d√©taill√©
    const reportPath = path.join(process.cwd(), "indexation-analysis-report.json")
    fs.writeFileSync(
      reportPath,
      JSON.stringify(
        {
          timestamp: new Date().toISOString(),
          summary,
          detailedResults: results,
        },
        null,
        2,
      ),
    )

    console.log(`\nüíæ Rapport d√©taill√© sauvegard√©: ${reportPath}`)
    console.log("\nüéØ Prochaines √©tapes:")
    console.log("1. Corriger les probl√®mes SEO identifi√©s")
    console.log("2. Red√©ployer le site avec les corrections")
    console.log("3. Soumettre le sitemap mis √† jour")
    console.log("4. Demander l'indexation dans Google Search Console")
  } catch (error) {
    console.error("‚ùå Erreur lors de l'analyse:", error.message)
  }
}

if (require.main === module) {
  main()
}

module.exports = { analyzeUrl, problematicUrls }
